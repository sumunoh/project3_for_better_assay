# For Better Essay :books:
#  한국어 도서 말뭉치를 활용한 인공지능 서비스, 문해력 향상 프로그램 
   
### 공모전 최우수상(1등) 수상

![공모전](https://user-images.githubusercontent.com/92708600/150311483-d6026347-6c67-458c-a7bb-aaf4fda0eeb9.jpg)
![최우수상1](https://user-images.githubusercontent.com/92708600/150310714-e6863c95-3bb7-429b-a4a5-5eb9e25385c5.jpg)

## 결과 / [Result] 


![4](https://user-images.githubusercontent.com/86215536/145538415-cb151969-21a8-4b71-a299-c824e3f3cd62.jpg)


[<strong> - 시연영상 </strong>](https://github.com/O-per/cakd3_Project3/blob/main/_video.md)




 <br>

## 설명 / [Description]


최근 이슈가 되고 있는 어린 세대의 문해력 저하현상이라는 문제의식에서 출발하여, 중·고등학생을 타겟으로 문해력 향상을 위해 논술을 포함한 글쓰기 학습 및 독서학습에서 가장 자주 사용하는 학습인 문서 요약 연습을 할 수 있는 서비스를 웹 서비스를 이용하여 제공합니다.   



## 프로젝트 절차 / [Procedure]


### 시나리오 설계 / [Scenario Design]
: 한국어 도서 말뭉치에서 특정 길이의 독해 지문을 제공합니다. 이후 학습모델이 기계 요약문을 생성해주면, 사용자가 입력한 요약문과 기계가 요약한 요악문을 비교 및 평가하여 정확도를 출력합니다. 
0.8 이상이면 Perfect, 0.6 이상 0.8 미만이면 Great, 0.4 이상 0.6 미만이면 Good, 0.4 미만이면 Try again 이라는 값이 뜨도록 합니다.

### 데이터 구축 및 전처리 / [Data Building and Preprocessing]
   1. json파일 형태로 되어있는 데이터안에서 필요한 부분만을 정제하여 csv형태로 정리합니다. 
   2. 문단이 아닌 문장의 형태로 구현되어 있는 데이터의 경우 문단의 형태로 정제합니다.
   3. 난이도를 고려한 서비스 구현을 위한 컬럼을 생성합니다. 
   4. 말뭉치 데이터를 카테고리별로 고려하여 병합합니다.
   5. 서비스 구현시 빠른 구동 속도를 위하여 데이터를 DB의 형태로 정제합니다.

### 사전 학습 / [ET5]
: 대용량 원시 텍스트로부터 빈칸 단어열 맞추기(T5 학습 유형)와 다음 단어 맞추기(GPT 학습 유형)를 동시에 사전학습(pre-train)하여 언어 이해와 언어 생성 능력을 향상 시킨 ETRI에서 개발한 한국어 이해생성 언어모델을 사용하였습니다.   
: 언어 모델은 ETRI의 ET5 학습 데이터 사용신청 페이지를 통해 사용허가협약서를 작성한 후 다운로드 하여 사용받았으며, 제 3자에게 무단 공유가 불가능하여 Github 저장소에는 업로드하지 않았습니다.   
: https://aiopen.etri.re.kr/service_dataset.php

### 파인튜닝 / [Fine Tuning]
: 사전 학습된 ET5를 주어진 문서의 특징에 맞는 요약문을 생성하도록 파인 튜닝을 진행하였습니다. 파인튜닝은 AI hub 개방데이터의 문서요약 텍스트(약 300자~1천자로 이루어진 문단 20만건과 각각의 문단에 대한 요약문 20만건으로 이루어진 데이터) 데이터를 활용하여 이루어졌습니다.

### 평가모델 / [BERT SCORE]
: 문장 요약 평가에 관습적으로 ROUGE score를 많이 사용하지만 ROUGE는 exact match로 평가해 문맥을 평가하지 못합니다. 따라서 단어간의 코사인 유사도를 통해 F1 score를 산출하기 때문에 문장간의 문맥을 평가할 수 있는 BertScore를 사용하였습니다.   
: BERT_Score의 기본 구동원리는 참조 문장과 모델이 생성한 문장을 contextual embedding하여 코사인 유사도를 구하고, 이후 Greedy matching을 통해 가장 높은 유사도를 가진 벡터를 뽑아 F1 score를 구합니다.   
: 저희 모델의 bert score는 0.8391입니다.   

### 웹서비스 구현 / [Web service Implementation]
   #### < Main >   
   네 가지의 주제를 선택하거나, ‘실력UP’을 선택하여 심화 버전을 학습할 수 있습니다.    
   #### < Topic>    
   네 가지의 주제보다 좀 더 다양한 주제를 안내합니다.    
   #### < Summary >   
   실질적으로 문단을 보고 사용자가 작성한 요약문을 평가할 수 있습니다.   
   상단에 4가지의 주제 및 심화 문단으로 요약문을 학습할 수 있는 버튼이 있습니다. 4가지의 주제는 주제별 600자 미만의 글들로 구성되어 있고, 심화 글쓰기는 랜덤 주제로 600자 이상의 글들로 구성되어 있습니다.    
   사용자는 주제별로 출력된 랜덤 문단을 보고 사용자 요약문을 직접 작성할 수 있습니다. 이 때, 타이머를 이용하여 학습 시간을 잴 수 있습니다.    
   요약문을 60자 이상, 200자 이내로 충분히 작성 후 ‘제출하기’를 누르면 기계요약문과 함께 평가된 스코어가 출력됩니다.   
   #### < User & Settings >   
   사용자의 정보와 웹 서비스의 여러가지 설정들을 조절하거나 확인할 수 있습니다.   


